{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "“IMDB_with_multiple_models_handout_TF_IDF,LSTM+FastText,FastText",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g_wM75MwAoEn"
      },
      "source": [
        "# Sentiment classification - close to the state of the art\n",
        "\n",
        "The task of classifying sentiments of texts (for example movie or product reviews) has high practical significance in online marketing as well as financial prediction. This is a non-trivial task, since the concept of sentiment is not easily captured.\n",
        "\n",
        "For this assignment you have to use the larger [IMDB sentiment](https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) benchmark dataset from Stanford, an achieve close to state of the art results.\n",
        "\n",
        "The task is to try out multiple models in ascending complexity, namely:\n",
        "\n",
        "1. TFIDF + classical statistical model (eg. RandomForest)\n",
        "2. LSTM classification model\n",
        "3. LSTM model, where the embeddings are initialized with pre-trained word vectors\n",
        "4. fastText model\n",
        "5. BERT based model (you are advised to use a pre-trained one and finetune, since the resource consumption is considerable!)\n",
        "\n",
        "You should get over 90% validation accuracy (though nearly 94 is achievable).\n",
        "\n",
        "You are allowed to use any library or tool, though the Keras environment, and some wrappers on top (ie. Ktrain) make your life easier.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QADQva7AoEq"
      },
      "source": [
        "__Groups__\n",
        "This assignment is to be completed individually, four weeks after the class has finished. For the precise deadline please see canvas.\n",
        "\n",
        "__Format of submission__\n",
        "You need to submit a pdf of your Google Collab notebooks.\n",
        "\n",
        "__Due date__\n",
        "Four weeks after the class has finished. For the precise deadline please see canvas.\n",
        "\n",
        "Grade distribution:\n",
        "1. TFIDF + classical statistical model (eg. RandomForest) (25% of the final grade)\n",
        "2. LSTM classification model (15% of the final grade)\n",
        "3. LSTM model, where the embeddings are initialized with pre-trained word vectors, e.g. fastText, GloVe etc. (15% of the final grade)\n",
        "4. fastText model (15% of the final grade)\n",
        "5. BERT based model (you are advised to use a pre-trained one and finetune it, since the resource consumption is considerable!) (30% of the final grade). For BERT you should get over 90% validation accuracy (though nearly 94% is achievable).\n",
        "\n",
        "\n",
        "__For each of the models, the marks will be awarded according to the following three criteria__:\n",
        "\n",
        "(1) The (appropriately measured) accuracy of your prediction for the task. The more accurate the prediction is, the better. Note that you need to validate the predictive accuracy of your model on a hold-out of unseen data that the model has not been trained with.\n",
        "\n",
        "(2) How well you motivate the use of the model - what in this model's structure makes it suited for representing sentiment? After using the model for the task how well you evaluate the accuracy you got for each model and discuss the main advantages and disadvantages the model has in the particular modelling task. At best you take part of the modelling to support your arguments.\n",
        "\n",
        "(3) The consistency of your take-aways, i.e. what you have learned from your analyses. Also, analyze when the model is good and when and where it does not predict well.\n",
        "\n",
        "Please make sure that you comment with # on the separates steps of the code you have produced. For the verbal description and analyses plesae insert markdown cells.\n",
        "\n",
        "\n",
        "__Plagiarism__: The Frankfurt School does not accept any plagiarism. Data science is a collaborative exercise and you can discuss the research question with your classmates, if you like. You must not copy any code or text though. Plagiarism will be prosecuted and will result in a mark of 0 and you failing this class.\n",
        "\n",
        "After carefully reading this document and having had a look at the data you may still have questions. Please submit those question to the public Q&A board in canvas and we will answer each question, so "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QpCsyyH2AoEu"
      },
      "source": [
        "# Data download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "gEwjTzd8rqjR",
        "outputId": "8152172c-ccd8-40df-9f22-379ef71f854b"
      },
      "source": [
        "!wget https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
        "!tar -xzf aclImdb_v1.tar.gz\n",
        "!ls"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-12-07 22:02:26--  https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n",
            "Resolving ai.stanford.edu (ai.stanford.edu)... 171.64.68.10\n",
            "Connecting to ai.stanford.edu (ai.stanford.edu)|171.64.68.10|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 84125825 (80M) [application/x-gzip]\n",
            "Saving to: ‘aclImdb_v1.tar.gz’\n",
            "\n",
            "aclImdb_v1.tar.gz   100%[===================>]  80.23M  69.0MB/s    in 1.2s    \n",
            "\n",
            "2021-12-07 22:02:27 (69.0 MB/s) - ‘aclImdb_v1.tar.gz’ saved [84125825/84125825]\n",
            "\n",
            "aclImdb  aclImdb_v1.tar.gz  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2cSoMkCB31T"
      },
      "source": [
        "### Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BR4CBeDcNcJ"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.utils import simple_preprocess"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "usXa4qYsrShG",
        "outputId": "3248434c-f97f-41ea-d653-b8eb1824761f"
      },
      "source": [
        "data = {}\n",
        "for split in [\"train\", \"test\"]:\n",
        "    data[split] = []\n",
        "    for sentiment in [\"neg\", \"pos\"]:\n",
        "        score = 1 if sentiment == \"pos\" else 0\n",
        "        path = os.path.join('aclImdb', split, sentiment)\n",
        "        file_names = os.listdir(path)\n",
        "        for f_name in file_names:\n",
        "            with open(os.path.join(path, f_name), \"r\") as f:\n",
        "                review = f.read()\n",
        "                data[split].append([review, score])\n",
        "\n",
        "np.random.shuffle(data[\"train\"])        \n",
        "data_train = pd.DataFrame(data[\"train\"],columns=['text', 'label'])\n",
        "print(data_train)\n",
        "np.random.shuffle(data[\"test\"])\n",
        "data_test = pd.DataFrame(data[\"test\"],columns=['text', 'label'])\n",
        "print(data_test)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                    text  label\n",
            "0      Red Rock West is one of those rare films that ...      1\n",
            "1      I still wonder why I watched this movie. Admit...      1\n",
            "2      This is an installment in the notorious Guinea...      0\n",
            "3      Randolph Scott is heading into Albuquerque to ...      1\n",
            "4      An apparent vanity project for Karin Mani (who...      0\n",
            "...                                                  ...    ...\n",
            "24995  Ashanti is a very 70s sort of film (1979, to b...      1\n",
            "24996  A brutally depressing script and some fine low...      1\n",
            "24997  I viewed this movie in DVD format. My copy may...      0\n",
            "24998  I just watched this movie. In one word: sucky!...      0\n",
            "24999  No day passes without a new released computer ...      1\n",
            "\n",
            "[25000 rows x 2 columns]\n",
            "                                                    text  label\n",
            "0      I had enjoyed the Masters of Horror Series unt...      0\n",
            "1      G&M started a the odd couple downstairs in Man...      0\n",
            "2      This movie was supposedly based on a non-ficti...      0\n",
            "3      Highlighting the acting of Sidney Poitier and ...      1\n",
            "4      First things first - though I believe Joel Sch...      0\n",
            "...                                                  ...    ...\n",
            "24995  A very hyped-up, slick, edgy reinterpretation....      0\n",
            "24996  After cleaning up Dodge City (with a little he...      1\n",
            "24997  I'm afraid I did not like this adaptation. Whe...      0\n",
            "24998  i had no idea what this movies was about, it j...      0\n",
            "24999  The action scenes was quite good. But the plot...      0\n",
            "\n",
            "[25000 rows x 2 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwiFWK8rCEv4"
      },
      "source": [
        "### Preprocess text\n",
        "Use gensim to process data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-erbERXW8Bo"
      },
      "source": [
        "data_train.iloc[:,0] = data_train.iloc[:,0].apply(lambda x :' '.join(simple_preprocess(x))) \n",
        "data_test.iloc[:,0] =data_test.iloc[:,0].apply(lambda x :' '.join(simple_preprocess(x)))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-GxVpczXdoY"
      },
      "source": [
        "# TF-IDF + Classic Model\n",
        " The first step is to Vectroize text into number,here use the method from sklearn. First build a vectorizer class, then fit the train_text into the class. Then transform test_test, So that train_text and test_text has same dimension."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e84MaUQUa0os"
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics import accuracy_score\n",
        "import xgboost as xgb\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxwOkahwX7UC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7ae50835-1f11-42d7-f5fc-2ded7988706c"
      },
      "source": [
        "vectorizer = TfidfVectorizer()\n",
        "X_train = vectorizer.fit_transform(data_train['text'])\n",
        "print('X_train.shape:' ,X_train.shape)\n",
        "X_test = vectorizer.transform(data_test['text'])\n",
        "print('X_test.shape:' ,X_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train.shape: (25000, 73293)\n",
            "X_test.shape: (25000, 73293)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BtlQK3wOYWr6"
      },
      "source": [
        "### Build Model\n",
        "To avoid overfitting, split 10% validation data from train_text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o10m0LV0YbWX"
      },
      "source": [
        "X_train_rf, X_valid_rf, y_train_rf, y_valid_rf = train_test_split(\n",
        "    X_train, data_train['label'], test_size=0.1, random_state=42)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YufvG0f6YyQv",
        "outputId": "ae7d7f62-4c96-47b3-f285-2a43444e3a9b"
      },
      "source": [
        "clf = RandomForestClassifier(n_estimators=200, max_depth=10,random_state = 10223)\n",
        "clf.fit(X_train_rf, y_train_rf)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, n_estimators=200, random_state=10223)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9xVyTuQ-Y0mE"
      },
      "source": [
        "y_predicted = clf.predict(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "uvAeWgjyY20U",
        "outputId": "eb01cc8c-6719-439f-accc-1b3787e020e7"
      },
      "source": [
        "accuracy_score(data_test['label'], y_predicted)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.82708"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdwxLeSicdeW"
      },
      "source": [
        "Here first get a accuracy of 82.70% on test data as base line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NMyZExcXPPc"
      },
      "source": [
        "# FastText model\n",
        "FastText model requires special format of input text, so first convert text into the suitable form. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_Ik9awyXOij"
      },
      "source": [
        "data_train_ft = data_train.copy()\n",
        "data_test_ft = data_test.copy()\n",
        "data_train_ft.iloc[:,1] = data_train_ft.iloc[:,1].apply(lambda x:'__label__'+str(x))\n",
        "data_test_ft.iloc[:,1] = data_test_ft.iloc[:,1].apply(lambda x:'__label__'+str(x))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZnbTYMVAHgj"
      },
      "source": [
        "import csv\n",
        "data_train_ft.to_csv('train.txt',index = False,\n",
        "                    sep = ' ',header = None,\n",
        "                    quoting = csv.QUOTE_NONE,\n",
        "                    quotechar = \"\",\n",
        "                    escapechar = \" \")\n",
        "data_test_ft.to_csv('test.txt', \n",
        "                   index = False, \n",
        "                   sep = ' ',\n",
        "                   header = None, \n",
        "                   quoting = csv.QUOTE_NONE, \n",
        "                   quotechar = \"\", \n",
        "                   escapechar = \" \")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hJ5yJcNzdfxQ",
        "outputId": "28e880f5-e227-4e06-a38a-606ab20e2ee8"
      },
      "source": [
        "!pip install fasttext"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting fasttext\n",
            "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 30.5 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 20 kB 36.6 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 30 kB 22.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 40 kB 17.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 51 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 61 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 68 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pybind11>=2.2\n",
            "  Using cached pybind11-2.8.1-py2.py3-none-any.whl (208 kB)\n",
            "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n",
            "Building wheels for collected packages: fasttext\n",
            "  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3123444 sha256=e5934e566498d86b38f66650e38a49a6861bdb051415f49c3a7ae323d436cd52\n",
            "  Stored in directory: /root/.cache/pip/wheels/4e/ca/bf/b020d2be95f7641801a6597a29c8f4f19e38f9c02a345bab9b\n",
            "Successfully built fasttext\n",
            "Installing collected packages: pybind11, fasttext\n",
            "Successfully installed fasttext-0.9.2 pybind11-2.8.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctJF3Lf_dkH_",
        "outputId": "2a6d8771-c4dc-41ea-b0a4-c52e7c127014"
      },
      "source": [
        "import fasttext\n",
        "fast_model = fasttext.train_supervised('train.txt')\n",
        "fast_model.test('test.txt')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 0.87708, 0.87708)"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdEg8UjadEEQ"
      },
      "source": [
        "Even with the default parameter setting, fasttext model behaves better than randomforest model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tSs3-uJasPge"
      },
      "source": [
        "lr =0.1\n",
        "dim = 128\n",
        "epoch = 10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hTcQ4CFr4DZ"
      },
      "source": [
        "fast_model_opt = fasttext.train_supervised('train.txt',lr=lr,dim=dim,epoch=epoch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRt7S4bYslUr",
        "outputId": "d61766f8-d1e6-40bf-e67c-5c1080536bec"
      },
      "source": [
        "fast_model_opt.test('test.txt')"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25000, 0.88356, 0.88356)"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv-lMRs9thUI"
      },
      "source": [
        "After a very limited space of parameter tuning, the model behaves slighly better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5fj6EGtAqWpO"
      },
      "source": [
        "# LSTM + FastText\n",
        "With a pretrained FastText model,train_data need to be converted to a matrix with dimension of fixed-length sequence keeping the first few words and word vector generated from the fast train model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54RfeXYQEjK6"
      },
      "source": [
        "!pip install seed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tEax9Alaq2tG"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Dense,Input,Embedding,GlobalAveragePooling1D,LSTM\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras import Model,backend\n",
        "from tensorflow.keras import regularizers\n",
        "import seed\n",
        "tf.random.set_seed(1234)\n",
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9gUym1D4hLK"
      },
      "source": [
        "lstm_size =64\n",
        "max_seq_len = 150"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DVWqDLwGSxk"
      },
      "source": [
        "def build_sentence_matrix(series):\n",
        "  '''Convert n-dim series to matrix (n,sequence_length,word_vector_dimension)'''\n",
        "  x = np.zeros((len(series),max_seq_len,fast_model_opt.dim))\n",
        "  y = np.zeros((len(series),max_seq_len,fast_model_opt.dim))\n",
        "  for idx,sentence in enumerate(series): \n",
        "    sentence = nltk.word_tokenize(sentence)\n",
        "    np_array = np.asarray([fast_model_opt.get_word_vector(word) for word in sentence])\n",
        "    if idx == len(series):\n",
        "      break\n",
        "    length = min(max_seq_len,len(np_array))\n",
        "    x[idx,:length-1,:] = np_array[:length-1,:]\n",
        "  return x     "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-agw4oYFLwj0"
      },
      "source": [
        "build_sentence_matrix(['this a string','this is another string']).shape # test how the function words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87l7NP7MSw6C"
      },
      "source": [
        "train_text_flstm = build_sentence_matrix(data_train.iloc[:,0]) # convert train text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu1SrWphgUq_"
      },
      "source": [
        "First build a simple model. Only has one LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dalqIWBy4GZq"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "inp = Input(shape=(max_seq_len,fast_model_opt.dim))\n",
        "x = LSTM(lstm_size)(inp)\n",
        "out = Dense(1,activation='sigmoid')(x)\n",
        "model = Model(inp, out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IvWakx07Wl4"
      },
      "source": [
        "model.compile(\n",
        "    tf.keras.optimizers.RMSprop(\n",
        "    learning_rate=0.01),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7KGd2y6L7Zlh",
        "outputId": "26a7436f-6fac-4902-e6d0-f4ada9e623ff"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 128)]        0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 64)                49408     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 49,473\n",
            "Trainable params: 49,473\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xnn9AFDPw6Fn"
      },
      "source": [
        "X_train_ls, X_valid_ls, y_train_ls, y_valid_ls = train_test_split(\n",
        "    train_text_flstm, data_train['label'], test_size=0.2, random_state=42)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ct__Sv3lHnLN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "baf7c3e8-e019-4d21-8240-a015e20bf930"
      },
      "source": [
        "model.fit(X_train_ls,y_train_ls,epochs=10,batch_size= 100,validation_data=(X_valid_ls,y_valid_ls))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 7s 16ms/step - loss: 0.6427 - accuracy: 0.6321 - val_loss: 0.4884 - val_accuracy: 0.7878\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.3616 - accuracy: 0.8552 - val_loss: 0.3072 - val_accuracy: 0.8768\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2838 - accuracy: 0.8832 - val_loss: 0.2612 - val_accuracy: 0.8982\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2608 - accuracy: 0.8964 - val_loss: 0.3847 - val_accuracy: 0.8052\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2510 - accuracy: 0.8986 - val_loss: 0.2391 - val_accuracy: 0.9014\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2423 - accuracy: 0.9032 - val_loss: 0.2603 - val_accuracy: 0.8954\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2356 - accuracy: 0.9058 - val_loss: 0.2345 - val_accuracy: 0.9066\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2335 - accuracy: 0.9083 - val_loss: 0.2328 - val_accuracy: 0.9134\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2298 - accuracy: 0.9081 - val_loss: 0.2297 - val_accuracy: 0.9090\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 2s 12ms/step - loss: 0.2264 - accuracy: 0.9108 - val_loss: 0.2779 - val_accuracy: 0.8848\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe8a01cb290>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a0nbsEVMrRAV"
      },
      "source": [
        "test_text_flstm = build_sentence_matrix(data_test.iloc[:,0])"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hxTu4xrvajWj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5762909f-c153-419c-d282-6a414313f8e0"
      },
      "source": [
        "model.evaluate(test_text_flstm,data_test.iloc[:,1],batch_size=100)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "250/250 [==============================] - 2s 6ms/step - loss: 0.4606 - accuracy: 0.8182\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.46056094765663147, 0.8181599974632263]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CcdG5Rsvhf9G"
      },
      "source": [
        "The model works well in dealing with overfiting, but seems have not enough capacity even after 20 batches traing. Try to add another layer to enlarge the capacity. Another aspect is the rather bad performance on test data compared to train and valid are both better. Try with more ramdomed validation data than validation_split in model.fit. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aSCrp9QKajhQ"
      },
      "source": [
        "keras.backend.clear_session()\n",
        "inp = Input(shape=(max_seq_len,fast_model_opt.dim))\n",
        "lstm1 = LSTM(lstm_size,return_sequences=True,return_state=True)(inp)\n",
        "lstm2 = LSTM(lstm_size)(lstm1[0])\n",
        "out = Dense(1,activation='sigmoid')(lstm2)\n",
        "model = Model(inp, out)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FhqyBY-Eh2z8"
      },
      "source": [
        "model.compile(\n",
        "    tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.02),\n",
        "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "    metrics=['accuracy'])"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "TnvD9Ugch3R_",
        "outputId": "e38d36cf-2d94-485c-e695-a805377652a7"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 150, 128)]        0         \n",
            "                                                                 \n",
            " lstm (LSTM)                 [(None, 150, 64),         49408     \n",
            "                              (None, 64),                        \n",
            "                              (None, 64)]                        \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 64)                33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 82,497\n",
            "Trainable params: 82,497\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dHQ5E6qh5ry",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "9bb6ab4d-2926-4bc2-8097-a2f382dba04c"
      },
      "source": [
        "model.fit(X_train_ls,y_train_ls,epochs=10,batch_size= 100,validation_data=(X_valid_ls,y_valid_ls))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200/200 [==============================] - 8s 28ms/step - loss: 0.6712 - accuracy: 0.5775 - val_loss: 0.6703 - val_accuracy: 0.4966\n",
            "Epoch 2/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.6549 - accuracy: 0.5994 - val_loss: 0.5355 - val_accuracy: 0.7750\n",
            "Epoch 3/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.4058 - accuracy: 0.8309 - val_loss: 0.2860 - val_accuracy: 0.8906\n",
            "Epoch 4/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.2890 - accuracy: 0.8841 - val_loss: 0.2743 - val_accuracy: 0.8898\n",
            "Epoch 5/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.2987 - accuracy: 0.8756 - val_loss: 0.3161 - val_accuracy: 0.8644\n",
            "Epoch 6/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.2774 - accuracy: 0.8880 - val_loss: 0.2656 - val_accuracy: 0.8904\n",
            "Epoch 7/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.2680 - accuracy: 0.8904 - val_loss: 0.2616 - val_accuracy: 0.8918\n",
            "Epoch 8/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.2552 - accuracy: 0.8951 - val_loss: 0.2970 - val_accuracy: 0.8718\n",
            "Epoch 9/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.2550 - accuracy: 0.8961 - val_loss: 0.2750 - val_accuracy: 0.8884\n",
            "Epoch 10/10\n",
            "200/200 [==============================] - 4s 21ms/step - loss: 0.2394 - accuracy: 0.9040 - val_loss: 0.2604 - val_accuracy: 0.8964\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fe79af93690>"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "HwpWLBgmh-Ro",
        "outputId": "3d0902b4-5af1-44f4-e223-40f3c2a9a441"
      },
      "source": [
        "model.evaluate(test_text_flstm,data_test.iloc[:,1],batch_size=50)"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1096: UserWarning: \"`binary_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "500/500 [==============================] - 4s 8ms/step - loss: 0.4172 - accuracy: 0.8279\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4172135293483734, 0.8278800249099731]"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test result is not as good as expected. More evaborate analysis is needed."
      ],
      "metadata": {
        "id": "MWATD-yr-OyA"
      }
    }
  ]
}